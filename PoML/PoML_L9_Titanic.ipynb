{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe4a5beb",
   "metadata": {},
   "source": [
    "# Titanic Survivor Prediction\n",
    "\n",
    "This notebook demonstrates encoding and scaling of features on the Titanic dataset from Stanford University."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609dfc3f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T20:23:32.930767Z",
     "start_time": "2023-12-03T20:23:32.901037Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a1c1be",
   "metadata": {},
   "source": [
    "## Download the Dataset\n",
    "\n",
    "Run the following cell to download the CSV file containing the data. Note that in this example we're again downloading the data the \"Pythonic\" way, rather than using the Terminal command wget as in some of the earlier notebooks.\n",
    "\n",
    "You can read more about the dataset on it's official homepage from [Stanford University](https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/problem12.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72071c74aa182dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv\"\n",
    "\n",
    "response = requests.get(data_url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    \n",
    "    # Save the file to your working directory\n",
    "    with open(\"titanic.csv\", \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    print(\"File downloaded successfully.\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Failed to download the file. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ca2a0c",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8def2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"titanic.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edd420d",
   "metadata": {},
   "source": [
    "## Exercise: Categorical Variable Encoding\n",
    "\n",
    "Define which variables should be handled as categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e740942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1498d085",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dummy_variables = []\n",
    "for categorical_feature in categorical_features:\n",
    "\n",
    "    # Perform one-hot encoding using pd.get_dummies\n",
    "    dummy_variables = pd.get_dummies(df[categorical_feature], prefix=categorical_feature)\n",
    "    all_dummy_variables.extend(dummy_variables)\n",
    "\n",
    "    # Append the new one-hot encoded variables to the original DataFrame\n",
    "    df = pd.concat([df, dummy_variables], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1486b753",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Define which features to use and what the target variable is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06168f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[all_dummy_variables + ['Age', 'Siblings/Spouses Aboard', 'Parents/Children Aboard', 'Fare']]\n",
    "target = df['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f856610b",
   "metadata": {},
   "source": [
    "## Training & Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac682574",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545e917e",
   "metadata": {},
   "source": [
    "## Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e39b750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree:\n",
    "# - max_depth: maximum depth of decision nodes (default: None)\n",
    "decision_tree = DecisionTreeClassifier(max_depth=None)\n",
    "\n",
    "# Random Forest\n",
    "# - n_estimators: number of individual decision trees used internally by the model (default: 100)\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Logistic Regression:\n",
    "# - max_iter: maximum number of iterations (default: 100)\n",
    "logistic_regression = LogisticRegression(max_iter=100)\n",
    "\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "# - n_neighbors: number of neighbors to consider (default: 5)\n",
    "# - weights: weighting of distance to neighbors: 'uniform' or 'distance' (default: 'uniform')\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Support Vector Machine:\n",
    "support_vector_machine = SVC()\n",
    "\n",
    "classifiers = [\n",
    "    decision_tree,\n",
    "    random_forest,\n",
    "    logistic_regression,\n",
    "    knn,\n",
    "    support_vector_machine\n",
    "]\n",
    "\n",
    "model_metrics = []\n",
    "for classifier in tqdm(classifiers):\n",
    "    \n",
    "    # Train the classifier\n",
    "    start_time = time.time()\n",
    "    trained_model = classifier.fit(X_train, y_train)\n",
    "    end_training_time = time.time()\n",
    "    training_time_elapsed = end_training_time - start_time\n",
    "    \n",
    "    # Apply trained classifier to test set\n",
    "    start_time = time.time()\n",
    "    predictions = trained_model.predict(X_test)\n",
    "    prediction_time = time.time()\n",
    "    prediction_time_elapsed = prediction_time - start_time\n",
    "    \n",
    "    # Measure model performance\n",
    "    score = classifier.score(X_test, y_test)\n",
    "    \n",
    "    # Record model metrics\n",
    "    model_metrics.append({\n",
    "        \"model\": trained_model.__class__.__name__,\n",
    "        \"training_time\": training_time_elapsed,\n",
    "        \"prediction_time\": prediction_time_elapsed,\n",
    "        \"score\": score,\n",
    "    })\n",
    "    \n",
    "# Print model metrics table\n",
    "scores_df = pd.DataFrame(model_metrics)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695548a6",
   "metadata": {},
   "source": [
    "## Exercise: Feature Scaling\n",
    "\n",
    "Determine which features should be scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35212198",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = []\n",
    "\n",
    "for column_to_scale in columns_to_scale:\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train[column_to_scale] = scaler.fit_transform(X_train[[column_to_scale]])\n",
    "    X_test[column_to_scale] = scaler.fit_transform(X_test[[column_to_scale]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbdfecc",
   "metadata": {},
   "source": [
    "### Visualize Density of Scaled Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59bed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use .plot.density() to plot scaled values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11f2691",
   "metadata": {},
   "source": [
    "## Model Training & Evaluation on Encoded + Scaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d53cdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = []\n",
    "for classifier in tqdm(classifiers):\n",
    "    \n",
    "    # Train the classifier\n",
    "    trained_model = classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Apply trained classifier to test set\n",
    "    predictions = trained_model.predict(X_test)\n",
    "    \n",
    "    # Measure model performance\n",
    "    score = classifier.score(X_test, y_test)\n",
    "    \n",
    "    # Record model metrics\n",
    "    model_metrics.append({\n",
    "        \"model\": trained_model.__class__.__name__,\n",
    "        \"score (with scaling)\": score,\n",
    "    })\n",
    "    \n",
    "scaled_scores_df = pd.DataFrame(model_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85de0670",
   "metadata": {},
   "source": [
    "## Score Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8345d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = scores_df.rename({'score': 'score (without scaling)'}, axis=1)\n",
    "pd.merge(scores_df, scaled_scores_df, on='model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d784696",
   "metadata": {},
   "source": [
    "## Decision Tree Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8df6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(max_depth=2)\n",
    "decision_tree = decision_tree.fit(features, target)\n",
    "\n",
    "tree.plot_tree(decision_tree, feature_names=X_train.columns[:-1], filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e973d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
