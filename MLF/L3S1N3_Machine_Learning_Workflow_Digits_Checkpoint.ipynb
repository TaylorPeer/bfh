{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ac1XDvdfYMsn"
   },
   "source": [
    "# Machine Learning Workflow Digits\n",
    "\n",
    "Based on working our way through the Machine Learning Workflow Iris notebook this notebook focuses on\n",
    "providing some exercise for establishing a machine learning workflow.\n",
    "\n",
    "1. Dataset Curation\n",
    "2. Dataset Pre-processing\n",
    "3. Dataset Provision\n",
    "4. Training Configuration\n",
    "5. Model Training Run\n",
    "6. Evaluation\n",
    "7. Iterative Optimisation\n",
    "\n",
    "You can read more a bit more on the dataset here: http://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1z3KwtYJYMso"
   },
   "source": [
    "# [Step 2] Dataset Pre-Processing\n",
    "\n",
    "The easiest way to load the Digits dataset is to use the built-in functionality of sci-kit learn.\n",
    "\n",
    "You can load the IRIS dataset with the following commmands:\n",
    "\n",
    "``from sklearn import datasets\n",
    "iris = datasets.load_digits()\n",
    "``\n",
    "\n",
    "However, to practice the initial steps of the machine learning workflow we will\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0DT0_RyYMso"
   },
   "source": [
    "## Exercise Downloading the Data\n",
    "\n",
    "The data for the Digits dataset can be downloaded from.\n",
    "\n",
    "https://archive.ics.uci.edu/dataset/81/pen+based+recognition+of+handwritten+digits\n",
    "\n",
    "On a Linux or Mac OS machine you can use the following commands to download the files to a local directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "jih1GVjaYMso"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-10-24 14:10:49--  http://archive.ics.uci.edu/ml/machine-learning-databases/pendigits/pendigits.tra\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified\n",
      "Saving to: ‘pendigits.tra’\n",
      "\n",
      "pendigits.tra           [    <=>             ] 490.33K   548KB/s    in 0.9s    \n",
      "\n",
      "2023-10-24 14:10:50 (548 KB/s) - ‘pendigits.tra’ saved [502098]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# wget is a handy command line utility that allows downloading the specified URL\n",
    "!wget http://archive.ics.uci.edu/ml/machine-learning-databases/pendigits/pendigits.tra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1Mil58iYMsq"
   },
   "source": [
    "## Exercise: Inspecting the  Digits Dataset Format\n",
    "\n",
    "Using the command line (or a text editor) we can inspect that dataset.\n",
    "\n",
    "The `!` operator will allow you to execute command line commands from a Jupyter cell.\n",
    "This should work on all supported operating systems (Mac OS, Linux, Windows).\n",
    "\n",
    "On a mac or linux machine you can make use of the following command line commands:\n",
    "\n",
    "* `head` : Show top n lines of a text file\n",
    "* `tail` : Show last n lines of a text file\n",
    "* `cat`  : Print full content of a text file\n",
    "* `wc -l`: Count number of lines of a text file\n",
    "\n",
    "On a Windows machine the following should work:\n",
    "\n",
    "* `more` : Show content of a text file (might hang in Jupyter)\n",
    "* `type` : Print content of a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "9p2EgfOcYMsq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 47,100, 27, 81, 57, 37, 26,  0,  0, 23, 56, 53,100, 90, 40, 98, 8\r\n",
      "  0, 89, 27,100, 42, 75, 29, 45, 15, 15, 37,  0, 69,  2,100,  6, 2\r\n",
      "  0, 57, 31, 68, 72, 90,100,100, 76, 75, 50, 51, 28, 25, 16,  0, 1\r\n",
      "  0,100,  7, 92,  5, 68, 19, 45, 86, 34,100, 45, 74, 23, 67,  0, 4\r\n",
      "  0, 67, 49, 83,100,100, 81, 80, 60, 60, 40, 40, 33, 20, 47,  0, 1\r\n",
      "100,100, 88, 99, 49, 74, 17, 47,  0, 16, 37,  0, 73, 16, 20, 20, 6\r\n",
      "  0,100,  3, 72, 26, 35, 85, 35,100, 71, 73, 97, 65, 49, 66,  0, 4\r\n",
      "  0, 39,  2, 62, 11,  5, 63,  0,100, 43, 89, 99, 36,100,  0, 57, 0\r\n",
      " 13, 89, 12, 50, 72, 38, 56,  0,  4, 17,  0, 61, 32, 94,100,100, 5\r\n",
      " 57,100, 22, 72,  0, 31, 25,  0, 75, 13,100, 50, 75, 87, 26, 85, 0\r\n"
     ]
    }
   ],
   "source": [
    "# head and tail are other useful command line utilities on a linux machine that allow us to see the first n or last\n",
    "# n lines of a text file.\n",
    "\n",
    "# Take your time to inspect both files with the head and tail commands. If you know that a file is not too long you can\n",
    "# also make use of the cat command that prints an entire files contents. For large files this is not advised as it can\n",
    "# easily overpower the javascript based rendering on the browser.\n",
    "\n",
    "!head pendigits.tra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EmQEw3fYMsq"
   },
   "source": [
    "# [Step 3] Provision: Loading the Dataset into a Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJJC0zCLYMsq"
   },
   "source": [
    "### Exercise: Load the Digits CSV files with pandas\n",
    "\n",
    "Lets create the test and train portions from the beginning based on the structure of the digits dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "Mo0ElgXuYMsq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>81</td>\n",
       "      <td>57</td>\n",
       "      <td>37</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>56</td>\n",
       "      <td>53</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "      <td>98</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>27</td>\n",
       "      <td>100</td>\n",
       "      <td>42</td>\n",
       "      <td>75</td>\n",
       "      <td>29</td>\n",
       "      <td>45</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>31</td>\n",
       "      <td>68</td>\n",
       "      <td>72</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>76</td>\n",
       "      <td>75</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "      <td>68</td>\n",
       "      <td>19</td>\n",
       "      <td>45</td>\n",
       "      <td>86</td>\n",
       "      <td>34</td>\n",
       "      <td>100</td>\n",
       "      <td>45</td>\n",
       "      <td>74</td>\n",
       "      <td>23</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>49</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>81</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1   2    3    4    5    6    7   8   9    10  11   12  13   14  15  16\n",
       "0  47  100  27   81   57   37   26    0   0  23   56  53  100  90   40  98   8\n",
       "1   0   89  27  100   42   75   29   45  15  15   37   0   69   2  100   6   2\n",
       "2   0   57  31   68   72   90  100  100  76  75   50  51   28  25   16   0   1\n",
       "3   0  100   7   92    5   68   19   45  86  34  100  45   74  23   67   0   4\n",
       "4   0   67  49   83  100  100   81   80  60  60   40  40   33  20   47   0   1"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can use the head() method in order to inspect the loaded dataframe.\n",
    "# Your result should look exactly like shown below.\n",
    "# If your result looks different then please have a look at the documentation of the parameters of the read_csv method\n",
    "# and load the data again.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "digits_df = pd.read_csv(\"pendigits.tra\", header=None)\n",
    "digits_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgiFWcAQYMsr"
   },
   "source": [
    "***Exercise***: Inspect the dataframes with the shape, ndim and len() attributes and methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "67jAXdNOYMsr"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7494.000000</td>\n",
       "      <td>7494.000000</td>\n",
       "      <td>7494.000000</td>\n",
       "      <td>7494.000000</td>\n",
       "      <td>7494.000000</td>\n",
       "      <td>7494.000000</td>\n",
       "      <td>7494.000000</td>\n",
       "      <td>7494.000000</td>\n",
       "      <td>7494.000000</td>\n",
       "      <td>7494.000000</td>\n",
       "      <td>7494.000000</td>\n",
       "      <td>7494.000000</td>\n",
       "      <td>7494.000000</td>\n",
       "      <td>7494.000000</td>\n",
       "      <td>7494.000000</td>\n",
       "      <td>7494.000000</td>\n",
       "      <td>7494.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37.384307</td>\n",
       "      <td>84.679343</td>\n",
       "      <td>40.005604</td>\n",
       "      <td>82.889512</td>\n",
       "      <td>50.878303</td>\n",
       "      <td>65.044436</td>\n",
       "      <td>51.471844</td>\n",
       "      <td>44.599680</td>\n",
       "      <td>57.129971</td>\n",
       "      <td>34.069122</td>\n",
       "      <td>61.417401</td>\n",
       "      <td>35.782092</td>\n",
       "      <td>54.699760</td>\n",
       "      <td>35.800774</td>\n",
       "      <td>46.813718</td>\n",
       "      <td>28.565386</td>\n",
       "      <td>4.430878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>33.322024</td>\n",
       "      <td>16.848420</td>\n",
       "      <td>26.256025</td>\n",
       "      <td>19.638582</td>\n",
       "      <td>34.927201</td>\n",
       "      <td>27.377341</td>\n",
       "      <td>30.680075</td>\n",
       "      <td>30.659478</td>\n",
       "      <td>33.680340</td>\n",
       "      <td>27.459989</td>\n",
       "      <td>37.130762</td>\n",
       "      <td>27.495836</td>\n",
       "      <td>22.599781</td>\n",
       "      <td>33.223611</td>\n",
       "      <td>41.531794</td>\n",
       "      <td>35.811094</td>\n",
       "      <td>2.876981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  7494.000000  7494.000000  7494.000000  7494.000000  7494.000000   \n",
       "mean     37.384307    84.679343    40.005604    82.889512    50.878303   \n",
       "std      33.322024    16.848420    26.256025    19.638582    34.927201   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       5.000000    76.000000    20.000000    70.000000    17.000000   \n",
       "50%      31.000000    89.000000    39.000000    89.000000    56.000000   \n",
       "75%      61.000000   100.000000    58.000000   100.000000    81.000000   \n",
       "max     100.000000   100.000000   100.000000   100.000000   100.000000   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  7494.000000  7494.000000  7494.000000  7494.000000  7494.000000   \n",
       "mean     65.044436    51.471844    44.599680    57.129971    34.069122   \n",
       "std      27.377341    30.680075    30.659478    33.680340    27.459989   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%      48.000000    28.000000    22.000000    30.000000     7.000000   \n",
       "50%      71.000000    54.000000    42.000000    60.000000    33.000000   \n",
       "75%      86.000000    75.000000    65.000000    88.000000    55.000000   \n",
       "max     100.000000   100.000000   100.000000   100.000000   100.000000   \n",
       "\n",
       "                10           11           12           13           14  \\\n",
       "count  7494.000000  7494.000000  7494.000000  7494.000000  7494.000000   \n",
       "mean     61.417401    35.782092    54.699760    35.800774    46.813718   \n",
       "std      37.130762    27.495836    22.599781    33.223611    41.531794   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%      25.000000    12.000000    41.000000     7.000000     0.000000   \n",
       "50%      74.000000    32.000000    53.000000    28.000000    39.000000   \n",
       "75%      98.000000    57.000000    69.000000    48.000000   100.000000   \n",
       "max     100.000000   100.000000   100.000000   100.000000   100.000000   \n",
       "\n",
       "                15           16  \n",
       "count  7494.000000  7494.000000  \n",
       "mean     28.565386     4.430878  \n",
       "std      35.811094     2.876981  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.000000     2.000000  \n",
       "50%       8.000000     4.000000  \n",
       "75%      51.000000     7.000000  \n",
       "max     100.000000     9.000000  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the digits dataframes you have created\n",
    "\n",
    "# len(digits_df)\n",
    "digits_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKq3IaM-YMsr"
   },
   "source": [
    "***Exercise: Create the Input and Response Dataframes for Test and Train Portions***\n",
    "\n",
    "Use the tooling we introduced before in order to inspect your newly created dataframes.\n",
    "\n",
    "* `head()`\n",
    "* `shape`\n",
    "* `dim`\n",
    "* `len()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "AJuHHLQNYMsr"
   },
   "outputs": [],
   "source": [
    "# Inspect your dataframes with the above tools in order to get familiar with them\n",
    "# Inspecting the intermediary artifacts in the machine learning workflow is a common and crucial task.\n",
    "# It is easy to imagine how one can be off when sub-setting or slicing through the input data by making a mistake.\n",
    "# These kind of errors are usually disastrous in terms of the outcome of the trained model. The earlier we catch them\n",
    "# the less expensive they are to fix.\n",
    "\n",
    "# Randomize/shuffle the dataframe\n",
    "digits_df.sample(frac=1)\n",
    "\n",
    "# Take 80% of the data for training and 20% for testing:\n",
    "size_training_set = int(len(digits_df) * 0.8)\n",
    "training_df = digits_df[:size_training_set]\n",
    "testing_df = digits_df[size_training_set:]\n",
    "\n",
    "X_train = training_df[training_df.columns[:-1]]\n",
    "y_train = training_df[[training_df.columns[-1]]]\n",
    "\n",
    "X_test = testing_df[testing_df.columns[:-1]]\n",
    "y_test = testing_df[[testing_df.columns[-1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively: let scikit-learn do some of the work for us:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = digits_df[digits_df.columns[:-1]]\n",
    "y = digits_df[[digits_df.columns[-1]]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nprypPwdYMsr"
   },
   "source": [
    "# [Step 4] Training Configuration\n",
    "\n",
    "The next step consist of creating the configuration for the training.\n",
    "\n",
    "The main dependencies for choosing a training set up are:\n",
    "\n",
    "* The data used for training (data type, quality, amount)\n",
    "* The task we want to solve (what we want the machine learning system to achieve)\n",
    "\n",
    "Based on these two aspects designing the training set up consists of the following steps:\n",
    "\n",
    "1. Choose training algorithm\n",
    "2. Create initial configuration for training algorithm\n",
    "\n",
    "## Criteria for Choosing A ML Algorithm\n",
    "\n",
    "Some main criteria for choosing a training algorithm are the following:\n",
    "\n",
    "* Task Fit : I.e. can the task we want to solve with ML be solved with the given algorithm\n",
    "* Scalability: How scalable in terms of the shape (columns, rows) of the input data is the algorithm\n",
    "    * The amount of features has a major impact on the scalability of algorithms\n",
    "    * The amount of samples (rows) has a major impact on the execution time of the algorithm\n",
    "* Expected Performance: What is the expected accuracy of the algorithm.\n",
    "* Interpretability: How easy, hard is it to understand what is happening in the algorithm. How hard would it be to 'debug' the behaviour of the algorithm.\n",
    "* Updatable Learning: Can the learned model be updated with more data at a later stage.\n",
    "* Availability: In the pragmatic sense; is a trusty implementation of the algorithm available (also from a license perspective).\n",
    "* Solution requirements: Do we have requirements from the software solution side. Maximum latency, memory limitations, etc ... .\n",
    "\n",
    "As the above list highlights, choosing the 'right' algorithm is a complex tasks with many potential considerations.\n",
    "On the flip side it means that making the right choices has massive potential value.\n",
    "\n",
    "## Choosing an Initial Configuration\n",
    "\n",
    "The choice of an initial training configuration often depends mainly on:\n",
    "\n",
    "* Stats of the training data\n",
    "     * Hyperparameters often allow us to adjust the training to the amount of the training data\n",
    "* Experience or documented well working configurations\n",
    "     * This is often based on identifying `baselines` that worked well on data that we deem similar to our training data.\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3L_kQK1aYMss"
   },
   "source": [
    "## ML Task\n",
    "\n",
    "By now it should be pretty clear what task fits well with the detection of hand-written digit images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L240FSybYMss"
   },
   "source": [
    "## Exercise: Choose Classification Algorithm\n",
    "\n",
    "For this ML task we can consider a variety of classifiers available in sci-kit learn:\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
    "\n",
    "The above listing represent some very widely used main classes of classifiers.\n",
    "To proceed choose any of the above classifiers and instantiate it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "hPD3UXnAYMss"
   },
   "outputs": [],
   "source": [
    "# Exercise: Set up the logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = ...\n",
    "\n",
    "# Exercise: Try out some other models:\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zt4DtIQlYMss"
   },
   "source": [
    "# [Step 5] Model Training Run - Establishing a Baseline\n",
    "\n",
    "Algorithms in scikit-learn can be trained by using the `fit` method. Calling it `fit` is based on the process of `fitting` the model's weights (also called model parameters) during training.\n",
    "`Fitting` means that the weights of the model are adjusted during the training (a.k.a learning) phase based on the input data we have seen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIwdjNp4YMss"
   },
   "source": [
    "## Exercise: Establishing a Baseline\n",
    "\n",
    "Based on the choosen classifier and the test and train data, lets establish a first baseline for the digits dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "1zfQVDyxYMss"
   },
   "outputs": [],
   "source": [
    "trained_model = classifier.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_eximmpYMss"
   },
   "source": [
    "### Testing your trained model\n",
    "\n",
    "As before, use the `predict()` method of the trained model and test the classification by passing in new arrays or slicing part of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I_BOaFqQYMst"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6sOf5SpYMst"
   },
   "source": [
    "## [Step 6] Evaluation\n",
    "\n",
    "All machine learning models provide a default metric that can be accessed via the score method.\n",
    "\n",
    "Record your first baseline by using the score method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1o9jKx4KYMst"
   },
   "outputs": [],
   "source": [
    "trained_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPe6iIX3YMst"
   },
   "source": [
    "### Exercise: Confusion Matrix\n",
    "\n",
    "The following code allows us to instantiate and plot a confusion matrix.\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns; sns.set()\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    mat = confusion_matrix(array_expected_responses, trained_model.predict(test_input))\n",
    "\n",
    "    sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
    "    plt.xlabel('predicted value')\n",
    "    plt.ylabel('true value');\n",
    "\n",
    "\n",
    "\n",
    "A confusion matrix is a very handy tool to identify where the classifier is likely to make errors.\n",
    "\n",
    "The True Positive (correct decisions) are always depicted on the diagonal of the confusion matrix.\n",
    "If the axis are labeled like in the example configuration below it is easy to identify the errors the model makes.\n",
    "\n",
    "Adapt the above code to create a confusion matrix for your classifier.\n",
    "Evaluate the result of different classifiers.\n",
    "\n",
    "* Do different classifiers make different kinds of mistakes?\n",
    "* Can we identify any patterns in the behaviour of classifiers?\n",
    "* Using the oonfusion matrix to identify the different classifiers should give you a feeling for its usefulness. A score is only a number and does not provide much else. The confusion matrix allows us to develop more insights with regard to the actual behaviour of a trained model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9B5x0Vj3YMst",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mat = confusion_matrix(y_test, trained_model.predict(X_test))\n",
    "plt.subplots(figsize=(10, 10))\n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False, fmt='.3g')\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvwCDAdnYMst"
   },
   "source": [
    "### Exercise: Cross-Validation\n",
    "\n",
    "As we learnt before it is common practice to operate based on a split of test and train data.\n",
    "\n",
    "Testing with unseen data is more realistic than executing the test with data that has already been processed by the trained model.\n",
    "\n",
    "However, we have also seen that the actual split (i.e. which samples end up in train and which in test) can have quite a significant impact on the observed performance.\n",
    "\n",
    "In order to mitigate this effect the method of cross-validation has been invented.\n",
    "Cross-validation simply means that I attempt to split my data `n` times into test and train portions and then run and evaluate my model `n` times with these different splits.\n",
    "\n",
    "One generally speaks of n-fold cross-validation. That means, if we speak of 10-fold cross-validation we will split the data randomly 10 times into a test and train portion, run the training 10 times on these splits, and evaluate 10 times.\n",
    "\n",
    "The main goal is to evaluate outliers in terms of exceptionally good or bad performance that are mainly caused by generating a 'lucky' or 'bad' split of the data.\n",
    "\n",
    "Even though you are using cross-validation we should hold out a dedicated test set.\n",
    "\n",
    "The following link provides instructions of how to apply cross-validation:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/cross_validation.html#computing-cross-validated-metrics\n",
    "\n",
    "Please configure cross-validation and run evaluations on a couple of the classifiers with it.\n",
    "\n",
    "What are some limiting factors for applying cross-validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EpNxw7EgYMsu"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(...)\n",
    "print(scores)\n",
    "print(\"---\")\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
